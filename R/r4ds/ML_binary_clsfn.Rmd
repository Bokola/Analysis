---
title: "ML implementation in R"
author: "Basil"
date: "October 29, 2018"
output:
  pdf_document:
    toc: yes
    toc_depth: '3'
  html_document:
    highlight: tango
    number_sections: yes
    theme: united
    toc: yes
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

First, we install packages:

```{r, results='hide', message=FALSE}

ipk <- function(pkg) {
  new.pkg <- list.of.pkgs[!(list.of.pkgs %in% installed.packages()[,"Package"])]
  if(length(new.pkg)) install.packages(new.pkg,  dependencies = T)
  sapply(pkg, require, character.only = T)
}
# packages used
list.of.pkgs <- c("AmesHousing", "caret", "data.table", "dplyr", "ggplot2", "gbm", "glmnet", "h2o", "pdp",  "pROC", "purrr", "ranger", "ROCR", "rsample", "vip", "xgboost", "Rcpp", "forecast","car","VGAM")
ipk(list.of.pkgs)

# package and session infoR
sessionInfo()
```
# **Implementation: Binary Classification**
We use the employee attrition data to illustrate various regularization concepts for a binary classification problem, where the goal is to predict whether or not an employee attrits ("Yes" vs. "No").
It is advisable to recode a binary response variable into zeros and ones.
```{r}
attrition <- rsample::attrition %>%
  #mutate(Attrition = recode(Attrition, "Yes" = 1, "No" = 0)) %>%
  mutate_if(is.ordered, factor, ordered = FALSE)
levels(attrition$Attrition) <- c(0,1)
```
## **`glmnet'**
As with regression, we perform some processing up-front to prepare for modelling with **glmnet**.We need to either ordinal encode or one-hot encode all categorical variables into numeric. Also, **glmnet** does not use the formula method (y ~ x) so we create our feature and target set and convert our features to a matrix. Since our response var is imbalanced, we use `rsample` and `strat` to perform a stratified sampling so that our training and testing data have similar proportion of response levels.
```{r}
#one-hot encode our data with model.matrix
one_hot <- model.matrix(~., attrition)[,-1] %>% as.data.frame()
names(one_hot)[names(one_hot) == "Attrition1"] <- "Attrition"
# create training and testing sets
set.seed(123)
split <- initial_split(one_hot, prop = 0.8, strata = "Attrition")
train <- training(split)
test <- testing(split)
#separate features from response var
train_x <- train %>% select(-Attrition) %>% as.matrix()
train_y <- train$Attrition
test_x <- test %>% select(-Attrition) %>% as.matrix()
test_y <- test$Attrition
# check that train & test sets have common response ratio
table(train_y) %>% prop.table()
table(test_y) %>% prop.table()
```
