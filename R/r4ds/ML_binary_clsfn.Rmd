---
title: "ML implementation in R"
author: "Basil"
date: "October 29, 2018"
output:
  pdf_document:
    toc: yes
    toc_depth: '3'
  html_document:
    highlight: tango
    number_sections: yes
    theme: united
    toc: yes
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

First, we install packages:

```{r, results='hide', message=FALSE}

ipk <- function(pkg) {
  new.pkg <- list.of.pkgs[!(list.of.pkgs %in% installed.packages()[,"Package"])]
  if(length(new.pkg)) install.packages(new.pkg,  dependencies = T)
  sapply(pkg, require, character.only = T)
}
# packages used
list.of.pkgs <- c("AmesHousing", "caret", "data.table", "dplyr", "ggplot2", "gbm", "glmnet", "h2o", "pdp",  "pROC", "purrr", "ranger", "ROCR", "rsample", "vip", "xgboost", "Rcpp", "forecast","car","VGAM")
ipk(list.of.pkgs)

# package and session infoR
sessionInfo()
```
# **Implementation: Binary Classification**
We use the employee attrition data to illustrate various regularization concepts for a binary classification problem, where the goal is to predict whether or not an employee attrits ("Yes" vs. "No").
It is advisable to recode a binary response variable into zeros and ones.
```{r}
attrition <- rsample::attrition %>%
  #mutate(Attrition = recode(Attrition, "Yes" = 1, "No" = 0)) %>%
  mutate_if(is.ordered, factor, ordered = FALSE)
levels(attrition$Attrition) <- c(0,1)
```
## **`glmnet'**
As with regression, we perform some processing up-front to prepare for modelling with **glmnet**.We need to either ordinal encode or one-hot encode all categorical variables into numeric. Also, **glmnet** does not use the formula method (y ~ x) so we create our feature and target set and convert our features to a matrix. Since our response var is imbalanced, we use `rsample` and `strat` to perform a stratified sampling so that our training and testing data have similar proportion of response levels.
```{r}
#one-hot encode our data with model.matrix
one_hot <- model.matrix(~., attrition)[,-1] %>% as.data.frame()
names(one_hot)[names(one_hot) == "Attrition1"] <- "Attrition"
# create training and testing sets
set.seed(123)
split <- initial_split(one_hot, prop = 0.8, strata = "Attrition")
train <- training(split)
test <- testing(split)
#separate features from response var
train_x <- train %>% select(-Attrition) %>% as.matrix()
train_y <- train$Attrition
test_x <- test %>% select(-Attrition) %>% as.matrix()
test_y <- test$Attrition
# check that train & test sets have common response ratio
table(train_y) %>% prop.table()
table(test_y) %>% prop.table()
```
### **Basic Implementation**
Similar to the regression problem, we apply a regularized classification model with `glmnet::glmnet()`. The difference is that for binary classification, we need to include `family = binomial`.
```{r}
# Apply ridge regression to attrition data
ridge = glmnet(
  x = train_x,
  y = train_y,
  family = "binomial",
  alpha = 0
)
plot(ridge, xvar = "lambda")
```
We can also access the coefficients for a model using `coef` and tidy the output with `tidy`. Here, we check out the top 10 largest absolute coefficient terms using the smallest and largest lambda values. We see that regardless of a large or small penalty parameter, working overtime and being a Sales Rep has the largest positive influence on the probability of attrition. Whereas being a Research Director and having high job involvement (among others) are the strongest influencers for reducing the probability of attrition.
```{r}
# Lambdas applied to penalty parameter
ridge$lambda %>% head()
# small lambda result in large coefficients
coef(ridge)[, 100] [-1] %>%
  tidy() %>%
  arrange(desc(abs(x)))
# large lambda result in small coefficients
coef(ridge)[, 1] [-1] %>%
  tidy() %>%
  arrange(desc(abs(x)))
```
At this point, we do not understand how much improvement we are experiencing in our loss function across various $\lambda$ values.

### **Tuning**
Recall: $\lambda$ is a tuning parameter that helps control our model from over-fitting to the training data. However, to identify the optimal $\lambda$ values, we need to perform cross-validation with `cv.glmnet`. Here we perform a 10-fold CV glmnet for both a ridge and lasso penalty.

By default, `cv.glmnet` uses deviance as the loss function for binomial classification but you could adjust `type.measure` to "auc", "mse", "mae", or "class" (missclassification).
```{r}
# apply cv ridge regression to attrition data
ridge <- cv.glmnet(
  x = train_x,
  y = train_y,
  family = "binomial",
  alpha = 0
)
# apply cv lasso regression to attrition data
lasso <- cv.glmnet(
  x = train_x,
  y = train_y,
  family = "binomial",
  alpha = 1
)
#plot results
par(mfrow = c(1,2))
plot(ridge, main = "Ridge penalty \n\n")
plot(lasso, main = "Lasso penalty \n\n")
```