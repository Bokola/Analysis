---
title: "ML implementation in R"
author: "Basil"
date: "October 29, 2018"
output:
  pdf_document:
    toc: yes
    toc_depth: '3'
  html_document:
    highlight: tango
    number_sections: yes
    theme: united
    toc: yes
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

First, we install packages:

```{r, results='hide', message=FALSE}

ipk <- function(pkg) {
  new.pkg <- list.of.pkgs[!(list.of.pkgs %in% installed.packages()[,"Package"])]
  if(length(new.pkg)) install.packages(new.pkg,  dependencies = T)
  sapply(pkg, require, character.only = T)
}
# packages used
list.of.pkgs <- c("AmesHousing", "caret", "data.table", "dplyr", "ggplot2", "gbm", "glmnet", "h2o", "pdp",  "pROC", "purrr", "ranger", "ROCR", "rsample", "vip", "xgboost", "Rcpp", "forecast","car","VGAM")
ipk(list.of.pkgs)

# package and session infoR
sessionInfo()
```
# **Implementation: Binary Classification**
We use the employee attrition data to illustrate various regularization concepts for a binary classification problem, where the goal is to predict whether or not an employee attrits ("Yes" vs. "No").
It is advisable to recode a binary response variable into zeros and ones.
```{r}
attrition <- rsample::attrition %>%
  #mutate(Attrition = recode(Attrition, "Yes" = 1, "No" = 0)) %>%
  mutate_if(is.ordered, factor, ordered = FALSE)
levels(attrition$Attrition) <- c(0,1)
```
## **`glmnet'**
As with regression, we perform some processing up-front to prepare for modelling with **glmnet**.We need to either ordinal encode or one-hot encode all categorical variables into numeric. Also, **glmnet** does not use the formula method (y ~ x) so we create our feature and target set and convert our features to a matrix. Since our response var is imbalanced, we use `rsample` and `strat` to perform a stratified sampling so that our training and testing data have similar proportion of response levels.
```{r}
#one-hot encode our data with model.matrix
one_hot <- model.matrix(~., attrition)[,-1] %>% as.data.frame()
names(one_hot)[names(one_hot) == "Attrition1"] <- "Attrition"
# create training and testing sets
set.seed(123)
split <- initial_split(one_hot, prop = 0.8, strata = "Attrition")
train <- training(split)
test <- testing(split)
#separate features from response var
train_x <- train %>% select(-Attrition) %>% as.matrix()
train_y <- train$Attrition
test_x <- test %>% select(-Attrition) %>% as.matrix()
test_y <- test$Attrition
# check that train & test sets have common response ratio
table(train_y) %>% prop.table()
table(test_y) %>% prop.table()
```
### **Basic Implementation**
Similar to the regression problem, we apply a regularized classification model with `glmnet::glmnet()`. The difference is that for binary classification, we need to include `family = binomial`.
```{r}
# Apply ridge regression to attrition data
ridge = glmnet(
  x = train_x,
  y = train_y,
  family = "binomial",
  alpha = 0
)
plot(ridge, xvar = "lambda")
```
We can also access the coefficients for a model using `coef` and tidy the output with `tidy`. Here, we check out the top 10 largest absolute coefficient terms using the smallest and largest lambda values. We see that regardless of a large or small penalty parameter, working overtime and being a Sales Rep has the largest positive influence on the probability of attrition. Whereas being a Research Director and having high job involvement (among others) are the strongest influencers for reducing the probability of attrition.
```{r}
# Lambdas applied to penalty parameter
ridge$lambda %>% head()
# small lambda result in large coefficients
coef(ridge)[, 100] [-1] %>%
  tidy() %>%
  arrange(desc(abs(x)))
# large lambda result in small coefficients
coef(ridge)[, 1] [-1] %>%
  tidy() %>%
  arrange(desc(abs(x)))
```
At this point, we do not understand how much improvement we are experiencing in our loss function across various $\lambda$ values.

### **Tuning**
Recall: $\lambda$ is a tuning parameter that helps control our model from over-fitting to the training data. However, to identify the optimal $\lambda$ values, we need to perform cross-validation with `cv.glmnet`. Here we perform a 10-fold CV glmnet for both a ridge and lasso penalty.

By default, `cv.glmnet` uses deviance as the loss function for binomial classification but you could adjust `type.measure` to "auc", "mse", "mae", or "class" (missclassification).
```{r}
# apply cv ridge regression to attrition data
ridge <- cv.glmnet(
  x = train_x,
  y = train_y,
  family = "binomial",
  alpha = 0
)
# apply cv lasso regression to attrition data
lasso <- cv.glmnet(
  x = train_x,
  y = train_y,
  family = "binomial",
  alpha = 1
)
#plot results
par(mfrow = c(1,2))
plot(ridge, main = "Ridge penalty \n\n")
plot(lasso, main = "Lasso penalty \n\n")
```
Our plots above illustrate the 10-fold CV deviance across the $\lambda$ values. The ridge model doesn't in any way improve the loss function as $\lamba$ increases, however, the lasso model indicates a slight improvement in the deviance as our penalty $\lambda$ increases, suggesting that regular logistic regression model likely overfits our data. But as we constrain it further, our deviance starts to increase. The numbers at the top of the plot refer to the number of variables in the model. Ridge regression does not force any variables to exactly zero so all features will remain in the model but we see the number of variables retained in the lasso model go down as our penalty increases, with the optimal model containing between 38-48 predictor variables.
The first and second vertical dashed lines represent the  
$\lambda$ value with the minimum deviance and the largest  $\lambda$ value within one standard error of the minimum deviance
```{r}
# Ridge model
min(ridge$cvm) # min deviance
ridge$lambda.min # lambda for this min deviance
ridge$cvm[ridge$lambda == ridge$lamda.1se] # 1 st.error of min deviance
ridge$lambda.1se # lambda for this deviance
# Lasso model
min(lasso$cvm) # min deviance
lasso$lambda.min # lambda for this min deviance
lasso$cvm[lasso$lambda == lasso$lambda.1se] #1 st.error of min deviance
lasso$lambda.1se # lambda for this deviance
```
