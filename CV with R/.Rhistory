gender = relevel(gender, ref = "man"),
fastfood_dum = relevel(as.factor(fastfood_dum), ref = 0),
fastfood = relevel(fastfood, ref = "rarely"),
)
LDL = LDL %>%
mutate_if(is.character, as.factor) %>%
mutate(gender_dum = relevel(as.factor(gender_dum), ref = '0'),
gender = relevel(gender, ref = "man"),
fastfood_dum = relevel(as.factor(fastfood_dum), ref = '0'),
fastfood = relevel(fastfood, ref = "rarely"),
)
m1 = lm(LDL ~ fastfood_dum, data = LDL)
est = tidy(m1)
est
LDL = LDL %>%
mutate_if(is.character, as.factor) %>%
mutate(gender_dum = relevel(as.factor(gender_dum), ref = '0'),
gender = relevel(gender, ref = "man"),
fastfood_dum = relevel(as.factor(fastfood_dum), ref = '0'),
fastfood = relevel(fastfood, ref = "rarely"),
)
m1 = lm(LDL ~ fastfood, data = LDL)
est = tidy(m1)
est
m2 = lm(LDL ~ fastfood_dum + age + gender_dum, data = LDL)
est2 = tidy(m2)
#summary(m2)
int2 = confint(m2) %>% as.data.frame() %>% tibble::rownames_to_column() %>%
`colnames<-`(c("term", "lower CI", "upper CI"))
out2 = left_join(est2, int2)
out2 = out2 %>% mutate(p.value = formatC(p.value, format = "e", digits = 4))
# out %>% gt()
out2 %>% knitr::kable(., caption = "Estimates of an additive model including the
three regressors\\label{tab:mod2_est}",
format = "pandoc")
m2 = lm(LDL ~ fastfood + age + gender, data = LDL)
est2 = tidy(m2)
#summary(m2)
int2 = confint(m2) %>% as.data.frame() %>% tibble::rownames_to_column() %>%
`colnames<-`(c("term", "lower CI", "upper CI"))
out2 = left_join(est2, int2)
out2 = out2 %>% mutate(p.value = formatC(p.value, format = "e", digits = 4))
# out %>% gt()
out2 %>% knitr::kable(., caption = "Estimates of an additive model including the
three regressors\\label{tab:mod2_est}",
format = "pandoc")
out2
m2$qr
summary(m2)
summary(m2)$resid
summary(m2)$r2
names(summary(m2))
summary(m1)
m1$coefficients
m1$coefficients[2]
unname(m1$coefficients[2])
unlist(m1$coefficients[2])
paste("Meseret Assefa", "Endale Alemayu", "Kedir Adem", "Basil Okola", sep = "\n")
home = ifelse(Sys.info()[["sysname"]] == "Linux", Sys.getenv("HOME"), Sys.getenv("USERPROFILE"))
home = gsub("\\\\", "/",home)
data_dir = file.path(home, "Google Drive (basil.okola@student.uhasselt.be)", "MSc. Stats Hasselt",
"y1 sem1", "Linear models")
fig_dir = file.path(home, "Google Drive (basil.okola@student.uhasselt.be)", "MSc. Stats Hasselt",
"y1 sem1", "Linear models")
knitr::opts_chunk$set(echo = TRUE,
# base_dir = "figures/",
fig.path = "figures/",
fig.align = "center",
fig.width = 6.5,
fig.height = 4,
dev = "png",
cache = TRUE,
message = FALSE,
warning = FALSE,
results = "markup")
options(tinytex.verbose = TRUE)
options(width = 100)
# options(scipen = 999)
knitr::opts_chunk$set(chunk_option1 = TRUE)
ipk = function(pkg){
new.pkg = list.of.pkgs[!(list.of.pkgs %in% .packages(all.available = TRUE))]
if(length(new.pkg)) install.packages(new.pkg, dependencies = TRUE)
suppressPackageStartupMessages({sapply(pkg, require, character.only = TRUE)})
}
list.of.pkgs = c("tidyverse", "magrittr", "knitr", "rmarkdown", "bookdown",
"skimr", "cowplot", "plyr", "data.table", "gt", "yardstick", "officer",
"flextable", "kableExtra", "patchwork", "car")
ipk(list.of.pkgs)
load(file.path(data_dir, 'LDL.RData'))
data1<-LDL
skim(data1)
means = LDL %>%
group_by(fastfood) %>%
dplyr::summarise(m = mean(LDL))
# as.numeric(means[2,2])
ggplot(LDL, aes(x = fastfood, y = LDL)) +
geom_boxplot() +
geom_jitter(color = "blue") +
xlab("fast food") + ylab("Blood LDL levels") +
# geom_hline(yintercept =as.numeric(means[1,2]), color = "red", linetype = "dotted") +
# annotate("text", x = "often", y = as.numeric(means[1,2]),
#          label = "mean (often)", vjust = -0.5, size = 3) +
# geom_hline(yintercept =as.numeric(means[2,2]), color = "green", linetype = "dotted") +
# annotate("text", x = "rarely", y = as.numeric(means[2,2]),
#          label = "mean (rarely)", vjust = -0.5, size = 3) +
theme(axis.title=element_text(size=14), axis.text = element_text(size=14))
m = lm(LDL ~ age, data = LDL)
ggplot(LDL, aes(age, LDL)) +
geom_point(color = "blue") +
geom_abline(intercept = m$coefficients[[1]], slope = m$coefficients[[2]]) +
xlab("age") + ylab("Blood LDL levels") +
theme(axis.title = element_text(size = 14), axis.text = element_text(size = 14))
means = LDL %>%
group_by(gender) %>%
dplyr::summarise(m = mean(LDL))
# as.numeric(means[2,2])
ggplot(LDL, aes(x = gender, y = LDL)) +
geom_boxplot() +
geom_jitter(color = "blue") +
xlab("gender") + ylab("Blood LDL levels") +
# geom_hline(yintercept =as.numeric(means[1,2]), color = "red", linetype = "dotted") +
# annotate("text", x = "man", y = as.numeric(means[1,2]),
#          label = "mean (man)", vjust = -0.5, size = 3) +
# geom_hline(yintercept =as.numeric(means[2,2]), color = "green", linetype = "dotted") +
# annotate("text", x = "woman", y = as.numeric(means[2,2]),
#          label = "mean (woman)", vjust = -0.5, size = 3) +
theme(axis.title=element_text(size=14), axis.text = element_text(size=14))
LDL = LDL %>%
mutate(gender_dum = ifelse(grepl("^man", gender), 0,1),
fastfood_dum = ifelse(grepl("rare", fastfood), 0,1))
LDL = LDL %>%
mutate_if(is.character, as.factor) %>%
mutate(gender_dum = relevel(as.factor(gender_dum), ref = '0'),
gender = relevel(gender, ref = "man"),
fastfood_dum = relevel(as.factor(fastfood_dum), ref = '0'),
fastfood = relevel(fastfood, ref = "rarely"),
)
m1 = lm(LDL ~ fastfood_dum, data = LDL)
est = tidy(m1)
int = confint(m1) %>% as.data.frame() %>% tibble::rownames_to_column() %>%
`colnames<-`(c("term", "lower CI", "upper CI"))
out = left_join(est, int)
out = out %>% mutate(p.value = formatC(p.value, format = "e", digits = 4))
# out %>% gt()
out %>% knitr::kable(., caption = "estimates and respective confidence intervals
for a model including the fastfood dummy variable\\label{tab:fastfood_est}",
format = "pandoc")
m2 = lm(LDL ~ fastfood + age + gender, data = LDL)
est2 = tidy(m2)
#summary(m2)
int2 = confint(m2) %>% as.data.frame() %>% tibble::rownames_to_column() %>%
`colnames<-`(c("term", "lower CI", "upper CI"))
out2 = left_join(est2, int2)
out2 = out2 %>% mutate(p.value = formatC(p.value, format = "e", digits = 4))
# out %>% gt()
out2 %>% knitr::kable(., caption = "Estimates of an additive model including the
three regressors\\label{tab:mod2_est}",
format = "pandoc")
e = residuals(m2)
YHat = predict(m2) # predicted
h = influence(m2)$h
p1<-ggplot(m2, aes(sample = rstandard(m2))) + geom_qq(color="blue") + stat_qq_line() +
ggtitle("Normal Q-Q Plot") +xlab("Theoretical Quantiles")+ylab("Sample Quantiles")+
theme(axis.title=element_text(size=14), axis.text = element_text(size=14)) +
theme(plot.title = element_text(hjust = 0.5))
p2<-ggplot()+geom_boxplot(aes(y=m2$residuals))+geom_jitter(color="blue")+
ggtitle("Boxplot of Residuals")+ylab("residuals")+
theme(axis.title=element_text(size=15), axis.text = element_text(size=15))
p1 | p2
q<-shapiro.test(data1$LDL) # Shapiro-Wilk normality test
Shapiro<-data.frame("statistic","p-value")
Shapiro[1,]<-c(q$statistic,q$p.value, options(digits=4))
colnames(Shapiro)<-c("Statistics","p-value") # change column names
knitr::kable(Shapiro,caption = "Shapiro-Wilk normality test\\label{tab:ShapiroWilk}")
vif(m2) %>% tidy() %>% `colnames<-`(c("variable", "vif")) %>% knitr::kable(caption = "variance inflation factor\\label{tab:vif}",
format = "pandoc")
p3<-ggplot(m2,aes(x=m2$fitted.values,y=m2$residuals^2))+geom_point(color="red")+  ## residuals vs fitted value
ggtitle("Residuals vs Fitted values")+ xlab("Fitted valus") + ylab("residuals")+geom_hline(yintercept=sum(m2$residuals^2)/40,linetype="dashed", color = "blue")+
theme(axis.title=element_text(size=15), axis.text = element_text(size=15))
p4<-ggplot(m2,aes(x=fastfood,y=m2$residuals^2))+geom_boxplot(color=c(2,3))+ ## residuals vs fast food
geom_jitter(color="blue")+geom_hline(yintercept=sum(m2$residuals^2)/40, linetype="dashed", color = "blue")+
ggtitle("Residuals vs Fast Food")+xlab("Fast food consumption") + ylab("Residuals")+
theme(axis.title=element_text(size=15), axis.text = element_text(size=15))
p5<-ggplot(m2,aes(x=age,y=m2$residuals^2))+geom_point(color="blue")+
ggtitle("Residuals vs Age")+geom_hline(yintercept=sum(m2$residuals^2)/40, linetype="dashed", color = "red")+
xlab("Age") + ylab("Residuals")+theme(axis.title=element_text(size=15), axis.text = element_text(size=15))
p6<-ggplot(m2,aes(x=gender,y=m2$residuals^2))+geom_boxplot(color=c(2,3))+ ## residuals vs gender
geom_jitter(color="blue")+geom_hline(yintercept=0, linetype="dashed", color = "blue")+
ggtitle("Residuals vs Gender")+ xlab("Gender") + ylab("Residuals")
(p3|p5)/(p4|p6)
cor(data1$LDL,data1$age)
e = residuals(m1)
YHat = predict(m1) # predicted
h = influence(m1)$h
LDL = LDL %>% mutate(e = e, YHat = YHat, h = h)
# fastfood
p1 = ggplot(LDL,aes(x = fastfood, y = e)) +
geom_boxplot() +geom_jitter(color = "blue") + geom_hline(yintercept = 0, linetype = "dotted", color = "red") +
xlab("fastfood") + ylab("residual") + ggtitle("Residual vs fastfood") +
theme(axis.title = element_text(size = 14), axis.text = element_text(size = 14)) +
theme_minimal_hgrid(10, rel_small = 1) +
theme(plot.title = element_text(hjust = 0.5))
# predicted
p2 = ggplot(LDL,aes(x = YHat, y = e)) +
geom_point(color = "blue") + geom_hline(yintercept = 0, linetype = "dotted", color = "red") +
xlab("predicted") + ylab("residual") + ggtitle("Residual vs predicted") +
theme(axis.title = element_text(size = 14), axis.text = element_text(size = 14)) +
theme_minimal_hgrid(10, rel_small = 1) +
theme(plot.title = element_text(hjust = 0.5))
p1 | p2
p2 = ggplot(LDL,aes(x = YHat, y = e)) +
geom_point(color = "blue") + geom_hline(yintercept = 0, linetype = "dotted", color = "red") +
xlab("predicted") + ylab("residual") + ggtitle("Residual vs predicted") +
theme(axis.title = element_text(size = 14), axis.text = element_text(size = 14)) +
theme_minimal_hgrid(10, rel_small = 1) +
theme(plot.title = element_text(hjust = 0.5))
p1 | p2
data(economics)
data(iris)
home = ifelse(Sys.info()[["sysname"]] == "Linux", Sys.getenv("HOME"), Sys.getenv("USERPROFILE"))
home = gsub("\\\\", "/",home)
data_dir = file.path(home, "Google Drive (basil.okola@student.uhasselt.be)", "MSc. Stats Hasselt",
"y1 sem1", "Linear models")
fig_dir = file.path(home, "Google Drive (basil.okola@student.uhasselt.be)", "MSc. Stats Hasselt",
"y1 sem1", "Linear models")
knitr::opts_chunk$set(echo = TRUE,
# base_dir = "figures/",
fig.path = "figures/",
fig.align = "center",
fig.width = 6.5,
fig.height = 4,
dev = "png",
cache = TRUE,
message = FALSE,
warning = FALSE,
results = "markup")
options(tinytex.verbose = TRUE)
options(width = 100)
# options(scipen = 999)
knitr::opts_chunk$set(chunk_option1 = TRUE)
list.of.pkgs = c("tidyverse", "magrittr", "rvest")
ipk = function(pkg){
new.pkg = list.of.pkgs[!(list.of.pkgs %in% .packages(all.available = TRUE))]
if(length(new.pkg)) install.packages(new.pkg, dependencies = TRUE)
suppressPackageStartupMessages({sapply(pkg, require, character.only = TRUE)})
}
list.of.pkgs = c("tidyverse", "magrittr", "rvest")
ipk(list.of.pkgs)
url = 'https://www.imdb.com/title/tt6723592/'
# reading the html code from website
read_html(url)
url = 'https://www.imdb.com/title/tt6723592/'
# reading the html code from website
webpage = read_html(url)
# using the html tag
castWithTag = html_nodes(webpage, "div")
length(castWithTag)
# using the id attribute
castWithId_node = html_nodes(webpage, "#titleCast")
html_text(castWithId_node)
# using the class attribute: note the '.'
castWithClass_node = html_nodes(webpage, ".cast_list")
html_text(castWithClass_node)
# using a more detailed attribute
cast = html_nodes(webpage, ".primary_photo + td a")
html_text(cast)
allTables = html_table(webpage, "table", header = FALSE)
html_table(webpage, ".cast_list", header = FALSE)
html_table(webpage, ".cast_list", header = FALSE)[[1]]
castTable = html_table(webpage, ".cast_list", header = FALSE)[[1]]
head(castTable)
html_attrs(castWithClass_node)
html_attr(cast, "href")
ipk = function(pkg){
new.pkg = list.of.pkgs[!(list.of.pkgs %in% .packages(all.available = TRUE))]
if(length(new.pkg)) install.packages(new.pkg, dependencies = TRUE)
suppressPackageStartupMessages({sapply(pkg, require, character.only = TRUE)})
}
list.of.pkgs = c("tidyverse", "magrittr", "rvest", "httr", "jsonlite")
ipk(list.of.pkgs)
res
res = GET("http://api.open-notify.org/astros.json")
res
format(Sys.time(), "%d %B, %Y")
format(Sys.time(), "%d" "%B", "%Y")
format(Sys.time(), "%d %B, %Y")
rawToChar(res$content)
data = fromJSON(rawToChar(res$content))
data
data <- fromJSON("https://api.github.com/users/hadley/orgs")
class(data)
jsonData = toJSON(data)
head(jsonData)
backAgain = fromJSON(jsonData)
class(backAgain)
identical(data, backAgain)
res = GET("http://api.open-notify.org/iss-pass.json",
query = list(lat = 40.7, lon = -74))
res
ipk = function(pkg){
new.pkg = list.of.pkgs[!(list.of.pkgs %in% .packages(all.available = TRUE))]
if(length(new.pkg)) install.packages(new.pkg, dependencies = TRUE)
suppressPackageStartupMessages({sapply(pkg, require, character.only = TRUE)})
}
list.of.pkgs = c("tidyverse", "magrittr", "rvest", "httr", "jsonlite", "DBI")
ipk(list.of.pkgs)
home
conn = dbConnect(
dbname = file.path(home, 'Downloads', 'chinook.db'),
drv = RSQLite::SQLite()
)
Sys.setenv("DB_USER" = "bokola")
Sys.getenv('DB_USER')
ipk = function(pkg){
new.pkg = list.of.pkgs[!(list.of.pkgs %in% .packages(all.available = TRUE))]
if(length(new.pkg)) install.packages(new.pkg, dependencies = TRUE)
suppressPackageStartupMessages({sapply(pkg, require, character.only = TRUE)})
}
list.of.pkgs = c("tidyverse", "magrittr", "rvest", "httr", "jsonlite", "DBI", "config", "vaultr")
ipk(list.of.pkgs)
conn
dbListTables(conn)
conn = dbConnect(
dbname = file.path(home, 'Downloads', 'chinook.db'),
drv = RSQLite::SQLite()
)
DBI::dbDisconnect(conn)
conn = dbConnect(
dbname = file.path(home, 'Downloads', 'chinook.db'),
drv = RSQLite::SQLite()
)
# DBI::dbDisconnect(conn)
dbListTables(conn)
DBI::dbDisconnect(conn)
home = ifelse(Sys.info()[["sysname"]] == "Linux", Sys.getenv("HOME"), Sys.getenv("USERPROFILE"))
home = gsub("\\\\", "/",home)
data_dir = file.path(home, "Google Drive (basil.okola@student.uhasselt.be)", "MSc. Stats Hasselt",
"y1 sem1", "Linear models")
fig_dir = file.path(home, "Google Drive (basil.okola@student.uhasselt.be)", "MSc. Stats Hasselt",
"y1 sem1", "Linear models")
knitr::opts_chunk$set(echo = TRUE,
# base_dir = "figures/",
fig.path = "figures/",
fig.align = "center",
fig.width = 6.5,
fig.height = 4,
dev = "png",
cache = TRUE,
message = FALSE,
warning = FALSE,
results = "markup")
options(tinytex.verbose = TRUE)
options(width = 100)
# options(scipen = 999)
knitr::opts_chunk$set(chunk_option1 = TRUE)
ipk = function(pkg){
new.pkg = list.of.pkgs[!(list.of.pkgs %in% .packages(all.available = TRUE))]
if(length(new.pkg)) install.packages(new.pkg, dependencies = TRUE)
suppressPackageStartupMessages({sapply(pkg, require, character.only = TRUE)})
}
list.of.pkgs = c("tidyverse", "magrittr", "rvest", "httr", "jsonlite", "DBI", "config", "vaultr")
ipk(list.of.pkgs)
url = 'https://www.imdb.com/title/tt6723592/'
# reading the html code from website
webpage = read_html(url)
# using the html tag
castWithTag = html_nodes(webpage, "div")
length(castWithTag)
# using the id attribute, note the '#'
castWithId_node = html_nodes(webpage, "#titleCast")
html_text(castWithId_node)
# using the class attribute: note the '.'
castWithClass_node = html_nodes(webpage, ".cast_list")
html_text(castWithClass_node)
# using a more detailed attribute
cast = html_nodes(webpage, ".primary_photo + td a")
html_text(cast)
allTables = html_table(webpage, "table", header = FALSE)
castTable = html_table(webpage, ".cast_list", header = FALSE)[[1]]
head(castTable)
html_attrs(castWithClass_node)
html_attr(cast, "href")
res = GET("http://api.open-notify.org/astros.json")
res
rawToChar(res$content)
data = fromJSON(rawToChar(res$content))
data
data <- fromJSON("https://api.github.com/users/hadley/orgs")
class(data)
jsonData = toJSON(data)
head(jsonData)
backAgain = fromJSON(jsonData)
class(backAgain)
identical(data, backAgain)
res = GET("http://api.open-notify.org/iss-pass.json",
query = list(lat = 40.7, lon = -74))
res
conn = dbConnect(
dbname = file.path(home, 'Downloads', 'chinook.db'),
drv = RSQLite::SQLite()
)
# DBI::dbDisconnect(conn)
conn = dbConnect(
dbname = file.path(home, 'Downloads', 'chinook.db'),
drv = RSQLite::SQLite()
)
# DBI::dbDisconnect(conn)
dbListTables(conn)
dbListFields(conn, "Artist")
dbListFields(conn, "Artists")
dbReadTable(conn, "Artists") %>% head(3)
ipk = function(pkg){
new.pkg = list.of.pkgs[!(list.of.pkgs %in% .packages(all.available = TRUE))]
if(length(new.pkg)) install.packages(new.pkg, dependencies = TRUE)
suppressPackageStartupMessages({sapply(pkg, require, character.only = TRUE)})
}
list.of.pkgs = c("tidyverse", "magrittr", "rvest", "httr", "jsonlite", "DBI", "config", "vaultr", "dbplyr")
ipk(list.of.pkgs)
tinytex::tlmgr_update()
install.packages("distill")
home = ifelse(Sys.info()[["sysname"]] == "Linux", Sys.getenv("HOME"), Sys.getenv("USERPROFILE"))
home = gsub("\\\\", "/",home)
_dir = file.path(home, "Analysis)", "R",
home = ifelse(Sys.info()[["sysname"]] == "Linux", Sys.getenv("HOME"), Sys.getenv("USERPROFILE"))
home = gsub("\\\\", "/",home)
dir = file.path(home, "Analysis)", "R",
"r4ds")
dir
home = ifelse(Sys.info()[["sysname"]] == "Linux", Sys.getenv("HOME"), Sys.getenv("USERPROFILE"))
home = gsub("\\\\", "/",home)
dir = file.path(home, "Analysis", "R",
"r4ds")
dir
distill::create_blog(dir = dir, title = "More into data.table")
dir = file.path(home, "Analysis")
distill::create_blog(dir = dir, title = "More into data.table")
distill::create_blog(dir = dir, title = "More into data.table")
home = ifelse(Sys.info()[["sysname"]] == "Linux", Sys.getenv("HOME"), Sys.getenv("USERPROFILE"))
home = gsub("\\\\", "/",home)
dir = file.path(home, "Analysis", "Distill websites")
distill::create_blog(dir = dir, title = "More into data.table")
ipk = function(pkg){
new.pkg = list.of.pkgs[!(list.of.pkgs %in% .packages(all.available = TRUE))]
if(length(new.pkg)) install.packages(new.pkg, dependencies = TRUE)
suppressPackageStartupMessages(sapply(pkg, library, character.only = TRUE))
}
list.of.pkgs = c('tidyverse', 'magrittr', 'nycflights13', 'lubridate')
ipk(list.of.pkgs)
home = ifelse(Sys.info()["sysname"] == 'Linux', Sys.getenv("HOME"), Sys.getenv("USERPROFILE")) %>%
gsub("\\\\", "/",.)
# 1. product of 2 numbers adding to 2020 ----------------------------------
data = file.path(home, "Downloads")
dat = read.delim(file.path(data,"dat1.txt")) %>% `colnames<-`(c("x1"))
dat =  dat %>%
mutate(., x2 = x1)
out = expand.grid(dat$x1, dat$x2) %>% `colnames<-`(c("x1", "x2"))
out1 = out %>%
mutate(., x3 = rowSums(.)) %>%
filter(., x3 == 2020) %>% slice(1) %>%
select(-x3) %>%
prod(.)
out1
install.packages("Pagedown")
install.packages("pagedown")
source('C:/Users/basil/Analysis/CV with R/render_cv.r', echo=TRUE)
knitr::opts_chunk$set(
results='asis',
echo = FALSE
)
library(magrittr) # For the pipe
source("cv_printing_functions.r")
# Read in all data and initialize a CV printer object
CV <- create_CV_object(
data_location = "https://docs.google.com/spreadsheets/d/1Cq7X-TA6iR0ZVFOD5QkfGxvZOWg3Zz2XnwAMz4YMInE",
pdf_mode = params$pdf_mode
)
# CV <- readr::read_rds('ddcv_cache.rds')
# When in pdf export mode the little dots are unaligned, so fix that with some conditional CSS.
if(params$pdf_mode) {
cat("
<style>
:root{
--decorator-outer-offset-left: -6.5px;
}
</style>")
}
# Build interactive network of positions colored by section
# and connected if they occurred in the same year
# datadrivencv::build_network_logo(CV$entries_data)
if(params$pdf_mode){
cat("CV online at
https://github.com/Bokola/Analysis/blob/master/CV%20with%20R/
cv_Basil Owiti Okola.html")
} else {
cat("[<i class='fas fa-download'></i> Download a PDF of this CV](https://github.com/Bokola/Analysis/blob/master/CV%20with%20R/cv_Basil Owiti Okola.pdf)")
}
CV %>% print_contact_info()
CV %>% print_skill_bars()
# Note the special double pipe so we modify the CV object in place
# CV %<>% print_text_block("intro")
CV %<>% print_section('education')
CV %<>% print_section('work_experience')
CV %<>%  print_section('Internship')
source('C:/Users/basil/Analysis/CV with R/render_cv.r', echo=TRUE)
home = ifelse(Sys.info()[["sysname"]] == "Linux", Sys.getenv("HOME"), Sys.getenv("USERPROFILE"))
home = gsub("\\\\", "/", home)
dir = file.path(home, "Analysis", "CV with R")
datadrivencv::use_datadriven_cv(full_name = file.path(dir,"Basil Owiti Okola"))
setwd(dir)
getwd()
source('~/render_cv.r', echo=TRUE)
source('C:/Users/basil/Analysis/CV with R/render_cv.r', echo=TRUE)
